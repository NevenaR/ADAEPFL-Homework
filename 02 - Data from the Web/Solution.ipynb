{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Homework 2 - IS-Academia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1) Obtain all the data for the Bachelor students, starting from 2007. Keep only the students for which you have an entry for both Bachelor semestre 1 and Bachelor semestre 6. Compute how many months it took each student to go from the first to the sixth semester. Partition the data between male and female students, and compute the average -- is the difference in average statistically significant?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get all students data, we need to get all parameters available to fetch the database by the REST API. To do so, we begin by request the section that display all `select` lists in the web page. Then, we extract for each options the humain readable name with his corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters_page = rq.get('http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_i_reportModel=133685247')\n",
    "filters = bfs(filters_page.text, 'html.parser')\n",
    "selects = filters.findAll('select')\n",
    "\n",
    "available_params = collections.defaultdict(dict)\n",
    "\n",
    "for select in selects:    \n",
    "    options = collections.defaultdict(list)\n",
    "    \n",
    "    for option in select.findAll('option'):\n",
    "        if option.attrs['value'] != 'null':\n",
    "            options[option.text] = option.attrs['value']\n",
    "        \n",
    "    available_params[select.attrs['name']] = options\n",
    "  \n",
    "available_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making params names readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all available parameters, but there are not easy to read. To improve this, we have made the choice to directly see the source code in the HTML page and make the correspondance because there are very few `select` box (so it's faster than extract this information directly in python).\n",
    "\n",
    "Every constants represent a parameter name. We define in addition a dictionary of default params needed in all requests we will make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SECTION_PARAM = 'ww_x_UNITE_ACAD' # like 'Informatique' => Computer Sciences\n",
    "YEAR_PARAM = 'ww_x_PERIODE_ACAD' # like '2016-2017'\n",
    "SEMESTER_PARAM = 'ww_x_PERIODE_PEDAGO' # like 'Bachelor semestre 1' => Bachelor semester 1\n",
    "TYPE_PARAM = 'ww_x_HIVERETE' # like 'Semestre d'automne' => Fall semester\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    'ww_x_GPS' : '-1',\n",
    "    'ww_i_reportModel' : '133685247',\n",
    "    'ww_i_reportModelXsl' : '133685270',\n",
    "}\n",
    "\n",
    "section_codes = available_params[SECTION_PARAM]\n",
    "year_codes = available_params[YEAR_PARAM]\n",
    "semester_codes = available_params[SEMESTER_PARAM]\n",
    "type_codes = available_params[TYPE_PARAM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we make a function that return a single dataframe from the html table extracted from a requested page.\n",
    "\n",
    "We try to get columns from table header. But in our case, all tables have two header rows, the first one is the title of the table and the second one is the colum names.\n",
    "\n",
    "Then, we fetch all rows to convert them to a single serie (list of column values in this row).\n",
    "Finally, we combine columns names and series in a new pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_page_to_dataframe(page):\n",
    "    soup = bfs(page.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    # Get columns names, skip the first column that show the section and year\n",
    "    columns = [column.text for column in table.find_all('th')[1:]]\n",
    "    \n",
    "    series = []\n",
    "    # Fetch all rows to a serie, skip the two first rows that represent header\n",
    "    for row in table.find_all('tr')[2:]:\n",
    "        serie = []\n",
    "        \n",
    "        # Fetch all columns, but skip the last one that is not in the header (badly structered html table)\n",
    "        for col in row.find_all('td')[:-1]:\n",
    "            serie.append(col.text)\n",
    "        series.append(serie)\n",
    "\n",
    "    # Create a dataframe from the columns and series variable\n",
    "    df = pd.DataFrame(series)\n",
    "    df.columns = columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are able to request a IS-Academia page containing the data table of students in a specific section, year and semester.\n",
    "We will store all data, to avoid multiple requests and DDOS the IS-Academia access. To do so, we will use pickle to serialize all data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data/'\n",
    "DATA_URL = 'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.html'\n",
    "\n",
    "# Create the directory Data if not exist\n",
    "if not os.path.exists('Data'):\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "\n",
    "# We focus only one data of students in bachelor and master\n",
    "bachelor_master_semester_codes = { \n",
    "    section_name : semester_codes[section_name] for section_name in semester_codes if section_name.startswith('Bachelor semestre') or section_name.startswith('Master semestre')\n",
    "}\n",
    "\n",
    "print('Start fetching data from ' + DATA_URL)\n",
    "\n",
    "for year_name, year_code in year_codes.items():\n",
    "\n",
    "    for semester_name, semester_code in bachelor_master_semester_codes.items():\n",
    "        \n",
    "        print('\\tFetch data for ' + year_name + ' ' + semester_name + '\\t: ', end=\"\", flush=True)\n",
    "\n",
    "        file_path = DATA_FOLDER + year_name + ' ' + semester_name\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "       \n",
    "            params = {\n",
    "                SECTION_PARAM : section_codes['Informatique'],\n",
    "                YEAR_PARAM : year_code,\n",
    "                SEMESTER_PARAM : semester_code,\n",
    "                TYPE_PARAM : 'null',\n",
    "                **DEFAULT_PARAMS\n",
    "            }\n",
    "\n",
    "            # We get a dataframe from a table in the html\n",
    "            try:\n",
    "                data = html_page_to_dataframe(rq.get(DATA_URL, params))\n",
    "\n",
    "                # We store data in binary file with pickle in the Data folder\n",
    "                data.to_pickle(file_path)\n",
    "                \n",
    "                print('Stored in ' + file_path)\n",
    "\n",
    "            except ValueError:\n",
    "                print('Unable to get data from ' + DATA_URL + ' with following params :')\n",
    "                for key, value in params.items():\n",
    "                    print('\\t\\t' + key + ' : ' + value)\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print('Already stored in ' + file_path)\n",
    "\n",
    "print('Fetching data done, see ' + DATA_FOLDER + ' folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Problem detected with \"2008-2009 Bachelor semestre 3\" and \"2007-2008 Bachelor semestre 3\", multiple table find (two entry instead of one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse bachelor data\n",
    "We will focus on bachelor students in computer sciences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bachelor_semester_codes = { \n",
    "    section_name : semester_codes[section_name] for section_name in semester_codes if section_name.startswith('Bachelor semestre')\n",
    "}\n",
    "\n",
    "# The variable contains a list of dataframe associated to a semester_name\n",
    "bachelor_dataframes = collections.defaultdict(pd.DataFrame)\n",
    "\n",
    "for semester_name, semester_code in bachelor_semester_codes.items():\n",
    "    \n",
    "    # We select the two interesting semester.\n",
    "    if (semester_name not in ['Bachelor semestre 6', 'Bachelor semestre 1']):\n",
    "        continue\n",
    "        \n",
    "    print('Compute for ' + semester_name)\n",
    "    \n",
    "    # The variable contains a list of dataframe related to a specific semester.\n",
    "    for year_name, year_code in year_codes.items():\n",
    "\n",
    "        file_path = DATA_FOLDER + year_name + ' ' + semester_name\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "\n",
    "            # We get a dataframe from a table in the html\n",
    "            bachelor_per_year = pd.read_pickle(file_path)\n",
    "\n",
    "            # We add the attribute year.\n",
    "            bachelor_per_year[semester_name] = year_name\n",
    "\n",
    "            # We add the result to \n",
    "            bachelor_dataframes[semester_name] =  pd.concat([bachelor_dataframes[semester_name],bachelor_per_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bachelor_data_semester6 = bachelor_dataframes['Bachelor semestre 6']\n",
    "bachelor_data_semester6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bachelor_data_semester1 = bachelor_dataframes['Bachelor semestre 1']\n",
    "bachelor_data_semester1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "student_bachelor_done = pd.merge(\n",
    "                            bachelor_data_semester1[['Civilité', 'Nom Prénom','No Sciper', 'Bachelor semestre 1']],\n",
    "                            bachelor_data_semester6[['No Sciper', 'Bachelor semestre 6']],\n",
    "                            on='No Sciper',\n",
    "                            how='inner',\n",
    "                            suffixes=('', '')\n",
    "                        )\n",
    "\n",
    "student_bachelor_done"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
