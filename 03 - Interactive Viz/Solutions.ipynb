{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Interactive Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import relativedelta\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import json\n",
    "from pprint import pprint\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from geopy.geocoders import GeoNames, Nominatim, GoogleV3\n",
    "import locale\n",
    "import seaborn as sns\n",
    "\n",
    "topojson_cantons = r'ch-cantons.topojson.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations (Test Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I also recommend you to use an intermediate viz step for debugging purposes, showing all the universties as markers in your map\"\n",
    "\n",
    "First let's begin to make an intermediate vizualisation : \n",
    "    - The Approved Amount is randomly generated \n",
    "    - We get the different name of canton in topojson_cantons file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(topojson_cantons) as data_file:    \n",
    "    ch_cantons_json = json.load(data_file)\n",
    "\n",
    "# We loop on the json file in order to get the initials of each canton.\n",
    "# Moreover we associate a random number to each cantons.\n",
    "cantons_id = [canton['id'] for canton in ch_cantons_json['objects']['cantons']['geometries']]\n",
    "data_test = pd.DataFrame({\n",
    "        'canton': cantons_id,\n",
    "        'value': np.random.randint(0, 100, len(cantons_id))\n",
    "    })\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We display the map with the dataframe built previously.\n",
    "map_test = folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "map_test.choropleth(\n",
    "    geo_path=topojson_cantons,\n",
    "    topojson='objects.cantons',\n",
    "    data=data_test,\n",
    "    columns=['canton', 'value'],\n",
    "    key_on='feature.id',\n",
    "    fill_color='PuBuGn',\n",
    "    fill_opacity=0.5,\n",
    "    line_opacity=0.7,\n",
    "    threshold_scale=list(np.linspace(data_test['value'].min(), data_test['value'].max(), 6)),\n",
    "    reset=True\n",
    ")\n",
    "map_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNSF data\n",
    "\n",
    "### Grant CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the P3_grantExport, we open it with a data parser in order to manipulate date more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data = pd.read_csv('Data/P3_GrantExport.csv', sep=';', parse_dates=['Start Date', 'End Date'])\n",
    "snsf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before putting the colums 'Project Number' as index of the dataframe we need to check if it's unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.columns = snsf_data.columns.str.replace(snsf_data.columns[0], 'Project Number')\n",
    "snsf_data['Project Number'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.set_index('Project Number', inplace=True)\n",
    "snsf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see with the dtypes method the values in 'Approved Amount' are objects.\n",
    "We need cast the differents values to numeric in order to be able to compute the sum easily. <br/>\n",
    "\n",
    "\n",
    "Here the can notice that 10910 value cannot be cast to numeric for two reason find in documentation :\n",
    "\n",
    "    - \"This amount is not indicated in the case of mobility fellowships since it depends on administrative factors,\n",
    "    typically the destination, cost of living, family allowances (if applicable) and exchange rate differences.\"\n",
    "    \n",
    "    - \"Also in the case of NCCRs this amount is not available in P3\"\n",
    "     \n",
    " \n",
    ">*After trying to get the result from NCCR we can conclude: <br/>\n",
    "From the http://www.snf.ch/SiteCollectionDocuments/nfs/nccr_guide_2016.pdf we can notice the cantons who reveive\n",
    "the nccr financial help are the cantons who reveive the most money from the P3 file. The result should not change\n",
    "a lot if we take in account the cnnr money.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data['Approved Amount'] = pd.to_numeric(snsf_data['Approved Amount'], errors='coerce')\n",
    "snsf_data['Approved Amount'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"This is the institution where the project will largely be carried out according to the application. Pick list. This field is only filled if the research is carried out at a Swiss institution, otherwise the field remains blank. In the case of mobility fellowships, it is generally left empty.\" <br/> *\n",
    "\n",
    "> As our study should be on swiss data, we decide to remove all null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We keep only the university not null, because those university are swiss.\n",
    "snsf_data_swiss = snsf_data[snsf_data['University'].notnull()].copy()\n",
    "snsf_data_swiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We check if we don't have Nan value anymore.\n",
    "snsf_data_swiss['University'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see if the mobility fellowship is  really important in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data_swiss[snsf_data_swiss['Funding Instrument'].str.contains(\"fellowships\")]['Funding Instrument'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data_swiss[snsf_data_swiss['Funding Instrument'].str.contains(\"Mobility\")]['Funding Instrument'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find location with university names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We get all the swiss university.\n",
    "universities_list = snsf_data['University'].dropna().unique()\n",
    "universities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a given Geocoders from geopy to locate a given university in the Switzerland country\n",
    "# geolocator: the Geocoders instance\n",
    "# file_path: file where result data will be keep, if the file already exist no now request will be done\n",
    "# universities: list of all universities to find\n",
    "def find_location(geolocator, file_path, universities=universities_list):\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        serie = pd.read_pickle(file_path)\n",
    "    else:\n",
    "        match_location = {}\n",
    "        progress_bar = FloatProgress(min=0, max=len(universities))\n",
    "        display(progress_bar)\n",
    "\n",
    "        for university in universities:\n",
    "            match_location[university] = geolocator.geocode(university + ' CH')\n",
    "            progress_bar.value += 1\n",
    "\n",
    "        serie = pd.Series(match_location)\n",
    "        serie.to_pickle(file_path)\n",
    "\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_file = r'env.json'\n",
    "\n",
    "with open('env.json') as file:    \n",
    "    env = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from GeoNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_geonames = GeoNames(username=env['GeoNames-Username'])\n",
    "data_location_geonames = find_location(geo_geonames, 'Data/geonmaes_locations.pickle')\n",
    "data_location_geonames.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_nominatim = Nominatim()\n",
    "data_location_nominatim = find_location(geo_nominatim, 'Data/nominatim_locations.pickle')\n",
    "data_location_nominatim.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from  Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_google = GoogleV3(api_key=env['GoogleMaps-Key'])\n",
    "data_location_google = find_location(geo_google, 'Data/google_locations.pickle')\n",
    "data_location_google.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that even by using three differents API the results are insufficient. We have decided to complete the missing data manually.\n",
    "\n",
    "To do so, we merge all results from API to make a single CSV file with all universities, canton and location. This file is temporary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "universities_cantons_geo = pd.DataFrame(snsf_data['University'].dropna().unique(), columns=['University'])  # We retrieve all universities\n",
    "\n",
    "universities_cantons_geo.head()\n",
    "\n",
    "# We convert series created by find_location function into DataFrame containing two columns: University and Location\n",
    "df_location_geonames = pd.DataFrame({'Location':data_location_geonames}).dropna()\n",
    "df_location_geonames.index.name = 'University'\n",
    "df_location_geonames.reset_index(inplace=True)\n",
    "df_location_nominatim = pd.DataFrame({'Location':data_location_nominatim}).dropna()\n",
    "df_location_nominatim.index.name = 'University'\n",
    "df_location_nominatim.reset_index(inplace=True)\n",
    "df_location_google = pd.DataFrame({'Location':data_location_google}).dropna()\n",
    "df_location_google.index.name = 'University'\n",
    "df_location_google.reset_index(inplace=True)\n",
    "\n",
    "def append_latitude(row, type):\n",
    "    '''\n",
    "    This functions check if a location has been found by a Geolocator for university passed as parameter.\n",
    "    If so, it returns latitude (respectively longitude).\n",
    "    \n",
    "    row: university (containing university name and location, if any)\n",
    "    type: type of coordinate we want to retrieve if a location is set\n",
    "    '''\n",
    "    \n",
    "    results = df_location_geonames[df_location_geonames['University'] == row['University']]['Location']\n",
    "    if results.empty:\n",
    "        results = df_location_nominatim[df_location_nominatim['University'] == row['University']]['Location']\n",
    "    if results.empty:\n",
    "        results = df_location_google[df_location_google['University'] == row['University']]['Location']\n",
    "\n",
    "    if not results.empty:\n",
    "        # First index filter: accessing first result of series 'results'\n",
    "        # Second index filter: accessing the coordinates\n",
    "        # Third index filter: accessing the latitude (respectively longitude)\n",
    "        return results.values[0][1][0 if type == 'Latitude' else 1]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "universities_cantons_geo['Latitude'] = universities_cantons_geo.apply(lambda row: append_latitude(row, 'Latitude'), axis=1)\n",
    "universities_cantons_geo['Longitude'] = universities_cantons_geo.apply(lambda row: append_latitude(row, 'Longitude'), axis=1)\n",
    "\n",
    "# We save our results in a CSV file\n",
    "universities_cantons_geo.set_index('University').to_csv('Data/universities_cantons_geo_tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head Data/universities_cantons_geo_tmp.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of all locations (API or manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to combine all results from API requests, and manually fetch on the web for others the canton and the coordinates. We put all in a CSV file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_location = pd.read_csv('Data/universities_cantons_geo.csv')\n",
    "match_location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset we have find 'NPO (Biblioth., Museen, Verwalt.) - NPO', after searching twe find out that si money given all arounf the swiss contry. We have the same result for `Firmen/Privatwirtschaft - FP`.<br/>\n",
    "For this reason the we decided to remove the Appoved amount of both.<br/>\n",
    "\n",
    "Furthermore 'Weitere' in english mean other so we can associate the amount of money to a specific canton.\n",
    "Finnaly for the same reason 'Nicht zuteilbar' mean not assignable, we can't keep it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On le garde ta mega fonction pour sortir le fichier CSV ? :p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge differents data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each university we compute the sum of 'Approved amount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_swiss_universities = pd.merge(\n",
    "    snsf_data_swiss[['University', 'Approved Amount']],\n",
    "    match_location[['University', 'Canton']],\n",
    "    on=['University'],\n",
    "    how='inner'\n",
    ")\n",
    "data_swiss_universities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_university = data_swiss_universities.groupby('University').sum()\n",
    "amount_by_university.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cantons we compute the sum of 'Approved amount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_cantons = data_swiss_universities.groupby('Canton').sum()\n",
    "amount_by_cantons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_cantons.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can notice the difference between the max and the min is huge. <br/> the vizualisation is not going to be very representative (with few colors variations) if we take those values. <br/>\n",
    "\n",
    "\n",
    "> For the reason we decide to apply the fourth root on values in order to reduce the gap between the amount of money given to each cantons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amount_by_cantons['Approved Amount Reduced'] = pow(amount_by_cantons['Approved Amount'], 1/5)\n",
    "amount_by_cantons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cantons_data = pd.DataFrame({\n",
    "        'Canton': cantons_id\n",
    "    })\n",
    "cantons_data.set_index('Canton', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the value for each canton, as we can notice in our data some canton does not appear.\n",
    "> We need to add them with a Appoved Amount equals to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_all_cantons = pd.merge(cantons_data, amount_by_cantons, right_index=True, left_index=True, how='left')\n",
    "amount_by_all_cantons.fillna(0, inplace=True)\n",
    "amount_by_all_cantons.reset_index(inplace=True)\n",
    "amount_by_all_cantons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We build the map from the data got before.\n",
    "map_final = folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "\n",
    "# You need to have the locale 'fr_CH.utf8' or 'fr_CH.UTF-8' install\n",
    "try:\n",
    "    locale.setlocale(locale.LC_MONETARY, 'fr_CH.utf8') # Linux locale\n",
    "except:\n",
    "    try:\n",
    "       locale.setlocale(locale.LC_MONETARY, 'fr_CH.UTF-8') # Mac locale\n",
    "    except:\n",
    "        print('Unable to set fr_CH.utf8 or fr_CH.UTF-8 locale, the currency will not be correct')\n",
    "\n",
    "# Add marker of universities\n",
    "universities_locations = match_location.set_index('University')[['Latitude', 'Longitude']].dropna()\n",
    "for university, row in universities_locations.iterrows():\n",
    "    amount = amount_by_university.loc[university]['Approved Amount']\n",
    "    message = university + ' (' + locale.currency( amount, grouping=True ) + ')'\n",
    "    marker = folium.Marker(row[['Latitude', 'Longitude']], popup=message)\n",
    "    map_final.add_children(marker)\n",
    "    \n",
    "value_column = 'Approved Amount Reduced'\n",
    "\n",
    "scale = list(\n",
    "    np.linspace(\n",
    "        amount_by_all_cantons[value_column].min(),\n",
    "        amount_by_all_cantons[value_column].max(),\n",
    "        6\n",
    "    )\n",
    ")\n",
    "\n",
    "map_final.choropleth(\n",
    "    geo_path=topojson_cantons,\n",
    "    data=amount_by_all_cantons,\n",
    "    columns=['Canton', value_column],\n",
    "    key_on='feature.id',\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    threshold_scale=scale,\n",
    "    legend_name='the fourth root of grant money by Swiss universities canton',\n",
    "    topojson='objects.cantons'\n",
    ")\n",
    "\n",
    "map_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Legend\n",
    "\n",
    ">> Colors: the fourth root of grant money by Swiss universities canton\n",
    "\n",
    ">> Markers: university names with the grant money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus - Röstigraben\n",
    "\n",
    "By reading wikipedia (https://en.wikipedia.org/wiki/Cantons_of_Switzerland#List), we decide that a canton have from 1 to 4 official spoken languages. We base our analysis on that. To make it easier, we divide the amount by the number of languages if a canton have more than 1 spoken languages.\n",
    "\n",
    "We will try to get approved amount by language in all the Switzerland, then we will try to make analysis regarding the area (km2).\n",
    "\n",
    "Firslty, we fetch wikipedia to get this HTML table and have the relation between canton and official languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wikipedia_page = rq.get('https://en.wikipedia.org/wiki/Cantons_of_Switzerland')\n",
    "wikipedia_soup = bfs(wikipedia_page.text, 'html.parser')\n",
    "\n",
    "# The table we need is the second table of the page, we can't make it simplier, where is not ID on it\n",
    "canton_table = pd.read_html(wikipedia_page.text)[1]\n",
    "\n",
    "new_header = canton_table.iloc[0] # grab the first row for the header\n",
    "canton_table = canton_table[1:-1] # take the data less the header row\n",
    "canton_table.rename(columns = new_header, inplace=True) # set the header row as the df header\n",
    "\n",
    "# Get only data that we need on the full dataframe from HTML table\n",
    "cantons_with_languages = canton_table[['Code', 'Canton', 'Official languages','Area (km2)']].copy()\n",
    "cantons_with_languages.set_index('Code', inplace=True)\n",
    "cantons_with_languages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add on column to every available language with a boolean (0=false / 1=true) set to true if the canton speak this language. This will be useful to group by language and additionaly to count the number of spoken languages in the canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spoken_languages = ['French', 'German', 'Italian', 'Romansh']\n",
    "\n",
    "series = {}\n",
    "for language in spoken_languages:\n",
    "    series[language] = pd.Series(0, index=cantons_with_languages.index)\n",
    "\n",
    "for row in cantons_with_languages.iterrows():\n",
    "    languages = row[1]['Official languages'].split(', ')\n",
    "    for language in languages:\n",
    "        series[language][row[0]] = 1\n",
    "\n",
    "for language, serie in series.items():\n",
    "    cantons_with_languages[language] = serie\n",
    "\n",
    "cantons_with_languages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the previous computed amount by canton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cantons_languages_amount = pd.concat([cantons_with_languages, amount_by_all_cantons.set_index('Canton')[['Approved Amount']]], axis=1)\n",
    "cantons_languages_amount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the number of spoken languages in the canton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cantons_languages_amount['Number of spoken languages'] = cantons_languages_amount['French'] + cantons_languages_amount['German'] + cantons_languages_amount['Italian'] + cantons_languages_amount['Romansh']\n",
    "cantons_languages_amount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assumptions: if there are two or more official languages in a canton, we divide equitably the amount of the canton by the number of spoken languages.\n",
    "\n",
    "We compute the real amount by language in a canton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cantons_languages_amount['Approved Amount per language'] = cantons_languages_amount['Approved Amount'] / cantons_languages_amount['Number of spoken languages']\n",
    "cantons_languages_amount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, we can have the sum by language of the approved amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_per_language = []\n",
    "for language in spoken_languages:\n",
    "    total_amount = cantons_languages_amount.groupby(language).sum()['Approved Amount per language'][1]\n",
    "    amount_per_language.append(total_amount)\n",
    "    print('Amount for ' + language + ' cantons: ' + locale.currency( total_amount, grouping=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see if there is a relation between the approved amount and the size of the area where there are a specific spoken language.\n",
    "\n",
    "> Assumptions: we use the same assumption made with amount by languages, but here with area (km2). If there are two or more official languages in a canton, we divide quitably the area of the canton by the number of spoken languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cantons_languages_amount['Area (km2)'] = pd.to_numeric(cantons_languages_amount['Area (km2)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_per_area_and_language = []\n",
    "for language in spoken_languages:\n",
    "    total_amount = cantons_languages_amount.groupby(language).sum();\n",
    "    total_per_area  =  total_amount['Approved Amount per language'][1]/ total_amount['Area (km2)'][1]\n",
    "    amount_per_area_and_language.append(total_per_area)\n",
    "    print('Amount per KM2 for ' + language + ' cantons: ' + locale.currency( total_per_area, grouping=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As we can see, despite the fact the french cantons earn less money in general, the concentration of university allow to earn more money per km2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_graph = pd.DataFrame(data={\n",
    "                             'Cantons': spoken_languages,\n",
    "                             'Amount per language': amount_per_language,\n",
    "                             'Amount per language and km2': amount_per_area_and_language\n",
    "                            })\n",
    "data_graph.set_index(['Cantons'], inplace=True)\n",
    "data_graph.plot(kind='bar',y='Amount per language')\n",
    "data_graph.plot(kind='bar',y='Amount per language and km2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_lang = {\n",
    "    'French': folium.Map(location=[46.8, 8.1], zoom_start=8),\n",
    "    'German': folium.Map(location=[46.8, 8.1], zoom_start=8),\n",
    "    'Italian': folium.Map(location=[46.8, 8.1], zoom_start=8),\n",
    "    'Romansh': folium.Map(location=[46.8, 8.1], zoom_start=8),\n",
    "    'All': folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "}\n",
    "\n",
    "map_data_lang = cantons_languages_amount.copy()\n",
    "map_data_lang.reset_index(inplace=True)\n",
    "\n",
    "color = {\n",
    "    'French': 'BuGn',\n",
    "    'German': 'BuPu',\n",
    "    'Italian': 'GnBu',\n",
    "    'Romansh': 'PuBu'\n",
    "}\n",
    "\n",
    "## Available :\n",
    "# 'BuGn', 'BuPu', 'GnBu', 'OrRd', 'PuBu', 'PuBuGn', 'PuRd', 'RdPu', 'YlGn', 'YlGnBu', 'YlOrBr', and 'YlOrRd'.\n",
    "\n",
    "opacite = [0.9,0.6,0.4,0.2]\n",
    "\n",
    "for idx, language in enumerate(spoken_languages):\n",
    "\n",
    "    map_data_lang[language] = pow(map_data_lang[language] * map_data_lang['Approved Amount per language'], 1/4)\n",
    "    \n",
    "    scale = list(\n",
    "        np.linspace(\n",
    "            map_data_lang[language].min(),\n",
    "            map_data_lang[language].max(),\n",
    "            6\n",
    "        )\n",
    "    )\n",
    "\n",
    "    map_lang[language].choropleth(\n",
    "        geo_path=topojson_cantons,\n",
    "        data=map_data_lang,\n",
    "        columns=['index', language],\n",
    "        key_on='feature.id',\n",
    "        fill_color=color[language],\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.1,\n",
    "        threshold_scale=scale,\n",
    "        legend_name='Grant money by Swiss ' + language + ' universities',\n",
    "        topojson='objects.cantons'\n",
    "    )\n",
    "    \n",
    "    map_lang['All'].choropleth(\n",
    "        geo_path=topojson_cantons,\n",
    "        data=map_data_lang,\n",
    "        columns=['index', language],\n",
    "        key_on='feature.id',\n",
    "        fill_color=color[language],\n",
    "        fill_opacity=opacite[idx],\n",
    "        line_opacity=0.1,\n",
    "        threshold_scale=scale,\n",
    "        legend_name='Grant money by Swiss ' + language + ' universities',\n",
    "        topojson='objects.cantons'\n",
    "    )\n",
    "\n",
    "    \n",
    "# Add marker of universities only in the full map or if the university is in a canton with the map language\n",
    "universities_locations_canton = match_location.set_index('University').dropna()\n",
    "for university, row in universities_locations_canton.iterrows():\n",
    "    for language, map_single in map_lang.items():\n",
    "        if language == 'All' or cantons_languages_amount.loc[row['Canton']][language] > 0:\n",
    "            amount = amount_by_university.loc[university]['Approved Amount']\n",
    "            message = university + ' - ' + row['Canton'] + ' (' + locale.currency( amount, grouping=True ) + ')'\n",
    "            marker = folium.Marker(row[['Latitude', 'Longitude']], popup=message)\n",
    "            map_single.add_children(marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Legend\n",
    "\n",
    ">> Colors: the fourth root of grant money by Swiss universities of a specific language\n",
    "\n",
    ">> Markers: university names with the grant money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_lang['French']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_lang['German']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_lang['Italian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_lang['Romansh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_lang['All']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "15079bc63e95481b82326ee0717671d6": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "191a783b301440a290cb46c945be1d3e": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "4166b5f5094348f0baf16159c78a9edc": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
