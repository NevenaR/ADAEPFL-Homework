{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Interactive Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import relativedelta\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import json\n",
    "from pprint import pprint\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from geopy.geocoders import GeoNames, Nominatim, GoogleV3\n",
    "import locale\n",
    "\n",
    "topojson_cantons = r'ch-cantons.topojson.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(topojson_cantons) as data_file:    \n",
    "    ch_cantons_json = json.load(data_file)\n",
    "\n",
    "cantons_id = [canton['id'] for canton in ch_cantons_json['objects']['cantons']['geometries']]\n",
    "data_test = pd.DataFrame({\n",
    "        'canton': cantons_id,\n",
    "        'value': np.random.randint(0, 100, len(cantons_id))\n",
    "    })\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_test = folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "map_test.choropleth(\n",
    "    geo_path=topojson_cantons,\n",
    "    topojson='objects.cantons',\n",
    "    data=data_test,\n",
    "    columns=['canton', 'value'],\n",
    "    key_on='feature.id',\n",
    "    fill_color='PuBuGn',\n",
    "    fill_opacity=0.5,\n",
    "    line_opacity=0.7,\n",
    "    threshold_scale=list(np.linspace(data_test['value'].min(), data_test['value'].max(), 6)),\n",
    "    reset=True\n",
    ")\n",
    "map_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNSF data\n",
    "\n",
    "### Grant CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data = pd.read_csv('Data/P3_GrantExport.csv', sep=';', parse_dates=['Start Date', 'End Date'])\n",
    "snsf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.columns = snsf_data.columns.str.replace(snsf_data.columns[0], 'Project Number')\n",
    "snsf_data['Project Number'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.set_index('Project Number', inplace=True)\n",
    "snsf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data['Approved Amount'] = pd.to_numeric(snsf_data['Approved Amount'], errors='coerce')\n",
    "snsf_data['Approved Amount'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data['University'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with differences slices of years\n",
    "\n",
    "From the doc : \"To a lesser extent, there may also be a problem with data quality,\n",
    "for example data on fellowships for prospective researchers is incomplete for the 1990’s. Moreover,\n",
    "data on SFGBM for advanced researchers is incomplete before 2005.\"\n",
    "\n",
    "> J'essai de voir si il y a des differences entre les années car les données devraient étre plus pertinentes à partir de 2000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_date = np.datetime64('2005');\n",
    "snsf_data_2005_2018 = snsf_data[snsf_data['Start Date'] >= limit_date ]\n",
    "snsf_data_2005_2018.head()\n",
    "snsf_data_2005_2018['University'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_date_sup = np.datetime64('2005');\n",
    "limit_date_inf = np.datetime64('2000');\n",
    "\n",
    "snsf_data_2000_2005 = snsf_data[(snsf_data['Start Date'] < limit_date_sup) & (snsf_data['Start Date'] >= limit_date_inf) ]\n",
    "snsf_data_2000_2005.head()\n",
    "snsf_data_2000_2005['University'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_date_sup = np.datetime64('2000');\n",
    "\n",
    "snsf_data_1975_2000 = snsf_data[(snsf_data['Start Date'] < limit_date_sup)]\n",
    "snsf_data_1975_2000.head()\n",
    "snsf_data_1975_2000['University'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test blanck attribute\n",
    "\n",
    "University field : \"This is the institution where the project will largely be carried out according to the application. Pick list. This field is only filled if the research is carried out at a Swiss institution, otherwise the field remains blank. In the case of mobility fellowships, it is generally left empty.\"\n",
    "\n",
    "> Je cheche quelles sont les attirbuts qui contiennent la \"mobility fellowship\" car c'est peut etre des universités suisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data['Funding Instrument Hierarchy'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data[snsf_data['Funding Instrument'].str.contains(\"fellowships\")]['Funding Instrument'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data[snsf_data['Funding Instrument'].str.contains(\"Mobility\")]['Funding Instrument'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_link_mobility = snsf_data[snsf_data['Funding Instrument'].str.contains(\"Mobility\")]['Funding Instrument'].value_counts(dropna=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_array = []\n",
    "for mobility_attribute in index_link_mobility:\n",
    "    index_array.append(mobility_attribute)\n",
    "index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_related_to_mobility_fellowship = snsf_data[snsf_data['Funding Instrument'].isin(index_array)].copy()\n",
    "data_related_to_mobility_fellowship['University'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_related_to_mobility_fellowship['Institution'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We keep only the university not null, because those university are swiss.\n",
    "snsf_data_swiss = snsf_data[snsf_data['University'].notnull()].copy()\n",
    "snsf_data_swiss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find location with university names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "universities_list = snsf_data['University'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a given Geocoders from geopy to locate a given university in the Switzerland country\n",
    "# geolocator: the Geocoders instance\n",
    "# universities: list of all universities to find\n",
    "def find_location(geolocator, universities=universities_list):\n",
    "\n",
    "    match_location = {}\n",
    "    progress_bar = FloatProgress(min=0, max=len(universities))\n",
    "    display(progress_bar)\n",
    "    \n",
    "    for university in universities:\n",
    "        match_location[university] = geolocator.geocode(university + ' CH')\n",
    "        progress_bar.value += 1\n",
    "        \n",
    "    return pd.Series(match_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_file = r'env.json'\n",
    "\n",
    "with open('env.json') as file:    \n",
    "    env = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from GeoNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_geonames = GeoNames(username=env['GeoNames-Username'])\n",
    "data_location_geonames = find_location(geo_geonames)\n",
    "data_location_geonames.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_nominatim = Nominatim()\n",
    "data_location_nominatim = find_location(geo_nominatim)\n",
    "data_location_nominatim.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from  Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_google = GoogleV3(api_key=env['GoogleMaps-Key'])\n",
    "data_location_google = find_location(geo_google)\n",
    "data_location_google.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of all locations (API or manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_location = pd.read_csv('Data/universities_cantons.csv')\n",
    "match_location['Canton'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquer pourquoi on enlève NPO (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_swiss_universities = pd.merge(\n",
    "    snsf_data_swiss[['University','Approved Amount']],\n",
    "    match_location,\n",
    "    on=['University'],\n",
    "    how='inner'\n",
    ")\n",
    "data_swiss_universities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_university = data_swiss_universities.groupby('University').sum()\n",
    "amount_by_university.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amount_by_cantons = data_swiss_universities.groupby('Canton').sum()\n",
    "amount_by_cantons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_cantons['Approved Amount Log'] = np.log(amount_by_cantons['Approved Amount'])\n",
    "amount_by_cantons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cantons_data = pd.DataFrame({\n",
    "        'Canton': cantons_id\n",
    "    })\n",
    "cantons_data.set_index('Canton', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_all_cantons = pd.merge(cantons_data, amount_by_cantons, right_index=True, left_index=True, how='left')\n",
    "amount_by_all_cantons.fillna(0, inplace=True)\n",
    "amount_by_all_cantons.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value_column = 'Approved Amount'\n",
    "\n",
    "scale = list(\n",
    "    np.linspace(\n",
    "        amount_by_all_cantons[value_column].min(),\n",
    "        amount_by_all_cantons[value_column].max(),\n",
    "        6\n",
    "    )\n",
    ")\n",
    "\n",
    "map_final = folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "map_final.choropleth(\n",
    "    geo_path=topojson_cantons,\n",
    "    topojson='objects.cantons',\n",
    "    data=amount_by_all_cantons,\n",
    "    columns=['Canton', value_column],\n",
    "    key_on='feature.id',\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    threshold_scale=scale\n",
    ")\n",
    "\n",
    "# You need to have the locale 'fr_CH.utf8' install\n",
    "locale_currency = 'fr_CH.utf8'\n",
    "try :\n",
    "    locale.setlocale(locale.LC_MONETARY, locale_currency)\n",
    "except:\n",
    "    print('Unable to set ' + locale_currency + ' locale, the currency will not be correct')\n",
    "\n",
    "# Add marker of universities find with google API\n",
    "for university, location in data_location_google.iteritems():\n",
    "    if location:\n",
    "        amount = amount_by_university.loc[university]['Approved Amount']\n",
    "        message = university + ' (' + locale.currency( amount, grouping=True ) + ')'\n",
    "        marker = folium.Marker(location[1], popup=message)\n",
    "        map_final.add_children(marker)\n",
    "\n",
    "map_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
