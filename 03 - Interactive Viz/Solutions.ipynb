{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Interactive Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import relativedelta\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import json\n",
    "from pprint import pprint\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from geopy.geocoders import GeoNames, Nominatim, GoogleV3\n",
    "import locale\n",
    "\n",
    "topojson_cantons = r'ch-cantons.topojson.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations (Test Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I also recommend you to use an intermediate viz step for debugging purposes, showing all the universties as markers in your map\"\n",
    "\n",
    "First let's begin to make an intermediate vizualisation : \n",
    "    - The Approved Amount is randomly generated \n",
    "    - We get the different name of canton in topojson_cantons file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(topojson_cantons) as data_file:    \n",
    "    ch_cantons_json = json.load(data_file)\n",
    "\n",
    "# We loop on the json file in order to get the initials of each canton.\n",
    "# Moreover we associate a random number to each cantons.\n",
    "cantons_id = [canton['id'] for canton in ch_cantons_json['objects']['cantons']['geometries']]\n",
    "data_test = pd.DataFrame({\n",
    "        'canton': cantons_id,\n",
    "        'value': np.random.randint(0, 100, len(cantons_id))\n",
    "    })\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We display the map with the dataframe built previously.\n",
    "map_test = folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "map_test.choropleth(\n",
    "    geo_path=topojson_cantons,\n",
    "    topojson='objects.cantons',\n",
    "    data=data_test,\n",
    "    columns=['canton', 'value'],\n",
    "    key_on='feature.id',\n",
    "    fill_color='PuBuGn',\n",
    "    fill_opacity=0.5,\n",
    "    line_opacity=0.7,\n",
    "    threshold_scale=list(np.linspace(data_test['value'].min(), data_test['value'].max(), 6)),\n",
    "    reset=True\n",
    ")\n",
    "map_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNSF data\n",
    "\n",
    "### Grant CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the P3_grantExport, we open it with a data parser in order to manipulate date more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data = pd.read_csv('Data/P3_GrantExport.csv', sep=';', parse_dates=['Start Date', 'End Date'])\n",
    "snsf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before putting the colums 'Project Number' as index of the dataframe we need to check if it's unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.columns = snsf_data.columns.str.replace(snsf_data.columns[0], 'Project Number')\n",
    "snsf_data['Project Number'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data.set_index('Project Number', inplace=True)\n",
    "snsf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see with the dtypes method the values in 'Approved Amount' are objects.\n",
    "We need cast the differents values to numeric in order to be able to compute the sum easily. <br/>\n",
    "\n",
    "\n",
    "Here the can notice that 10910 value cannot be cast to numeric for two reason find in documentation :\n",
    "\n",
    "    - \"This amount is not indicated in the case of mobility fellowships since it depends on administrative factors,\n",
    "    typically the destination, cost of living, family allowances (if applicable) and exchange rate differences.\"\n",
    "    \n",
    "    - \"Also in the case of NCCRs this amount is not available in P3\"\n",
    "     \n",
    " \n",
    ">*After trying to get the result from NCCR we can conclude: <br/>\n",
    "From the http://www.snf.ch/SiteCollectionDocuments/nfs/nccr_guide_2016.pdf we can notice the cantons who reveive\n",
    "the nccr financial help are the cantons who reveive the most money from the P3 file. The result should not change\n",
    "a lot if we take in account the cnnr money.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data['Approved Amount'] = pd.to_numeric(snsf_data['Approved Amount'], errors='coerce')\n",
    "snsf_data['Approved Amount'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"This is the institution where the project will largely be carried out according to the application. Pick list. This field is only filled if the research is carried out at a Swiss institution, otherwise the field remains blank. In the case of mobility fellowships, it is generally left empty.\" <br/> *\n",
    "\n",
    "> As our study should be on swiss data, we decide to remove all null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We keep only the university not null, because those university are swiss.\n",
    "snsf_data_swiss = snsf_data[snsf_data['University'].notnull()].copy()\n",
    "snsf_data_swiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We check if we don't have Nan value anymore.\n",
    "snsf_data_swiss['University'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see if the mobility fellowship is  really important in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data_swiss[snsf_data_swiss['Funding Instrument'].str.contains(\"fellowships\")]['Funding Instrument'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snsf_data_swiss[snsf_data_swiss['Funding Instrument'].str.contains(\"Mobility\")]['Funding Instrument'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find location with university names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We get all the swiss university.\n",
    "universities_list = snsf_data['University'].dropna().unique()\n",
    "universities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a given Geocoders from geopy to locate a given university in the Switzerland country\n",
    "# geolocator: the Geocoders instance\n",
    "# file_path: file where result data will be keep, if the file already exist no now request will be done\n",
    "# universities: list of all universities to find\n",
    "def find_location(geolocator, file_path, universities=universities_list):\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        serie = pd.read_pickle(file_path)\n",
    "    else:\n",
    "        match_location = {}\n",
    "        progress_bar = FloatProgress(min=0, max=len(universities))\n",
    "        display(progress_bar)\n",
    "\n",
    "        for university in universities:\n",
    "            match_location[university] = geolocator.geocode(university + ' CH')\n",
    "            progress_bar.value += 1\n",
    "\n",
    "        serie = pd.Series(match_location)\n",
    "        serie.to_pickle(file_path)\n",
    "\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_file = r'env.json'\n",
    "\n",
    "with open('env.json') as file:    \n",
    "    env = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from GeoNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_geonames = GeoNames(username=env['GeoNames-Username'])\n",
    "data_location_geonames = find_location(geo_geonames, 'Data/geonmaes_locations.pickle')\n",
    "data_location_geonames.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_nominatim = Nominatim()\n",
    "data_location_nominatim = find_location(geo_nominatim, 'Data/nominatim_locations.pickle')\n",
    "data_location_nominatim.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch from  Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_google = GoogleV3(api_key=env['GoogleMaps-Key'])\n",
    "data_location_google = find_location(geo_google, 'Data/google_locations.pickle')\n",
    "data_location_google.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that even by using three differents API the results are insufficient. We have decided to complete the missing data manually.\n",
    "\n",
    "To do so, we merge all results from API to make a single CSV file with all universities, canton and location. This file is temporary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "universities_cantons_geo = pd.DataFrame(snsf_data['University'].dropna().unique(), columns=['University'])  # We retrieve all universities\n",
    "\n",
    "universities_cantons_geo.head()\n",
    "\n",
    "# We convert series created by find_location function into DataFrame containing two columns: University and Location\n",
    "df_location_geonames = pd.DataFrame({'Location':data_location_geonames}).dropna()\n",
    "df_location_geonames.index.name = 'University'\n",
    "df_location_geonames.reset_index(inplace=True)\n",
    "df_location_nominatim = pd.DataFrame({'Location':data_location_nominatim}).dropna()\n",
    "df_location_nominatim.index.name = 'University'\n",
    "df_location_nominatim.reset_index(inplace=True)\n",
    "df_location_google = pd.DataFrame({'Location':data_location_google}).dropna()\n",
    "df_location_google.index.name = 'University'\n",
    "df_location_google.reset_index(inplace=True)\n",
    "\n",
    "def append_latitude(row, type):\n",
    "    '''\n",
    "    This functions check if a location has been found by a Geolocator for university passed as parameter.\n",
    "    If so, it returns latitude (respectively longitude).\n",
    "    \n",
    "    row: university (containing university name and location, if any)\n",
    "    type: type of coordinate we want to retrieve if a location is set\n",
    "    '''\n",
    "    \n",
    "    results = df_location_geonames[df_location_geonames['University'] == row['University']]['Location']\n",
    "    if results.empty:\n",
    "        results = df_location_nominatim[df_location_nominatim['University'] == row['University']]['Location']\n",
    "    if results.empty:\n",
    "        results = df_location_google[df_location_google['University'] == row['University']]['Location']\n",
    "\n",
    "    if not results.empty:\n",
    "        # First index filter: accessing first result of series 'results'\n",
    "        # Second index filter: accessing the coordinates\n",
    "        # Third index filter: accessing the latitude (respectively longitude)\n",
    "        return results.values[0][1][0 if type == 'Latitude' else 1]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "universities_cantons_geo['Latitude'] = universities_cantons_geo.apply(lambda row: append_latitude(row, 'Latitude'), axis=1)\n",
    "universities_cantons_geo['Longitude'] = universities_cantons_geo.apply(lambda row: append_latitude(row, 'Longitude'), axis=1)\n",
    "\n",
    "# We save our results in a CSV file\n",
    "universities_cantons_geo.set_index('University').to_csv('Data/universities_cantons_geo_tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head Data/universities_cantons_geo_tmp.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of all locations (API or manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to combine all results from API requests, and manually fetch on the web for others the canton and the coordinates. We put all in a CSV file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_location = pd.read_csv('Data/universities_cantons_geo.csv')\n",
    "match_location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset we have find 'NPO (Biblioth., Museen, Verwalt.) - NPO', after searching twe find out that si money given all arounf the swiss contry. We have the same result for `Firmen/Privatwirtschaft - FP`.<br/>\n",
    "For this reason the we decided to remove the Appoved amount of both.<br/>\n",
    "\n",
    "Furthermore 'Weitere' in english mean other so we can associate the amount of money to a specific canton.\n",
    "Finnaly for the same reason 'Nicht zuteilbar' mean not assignable, we can't keep it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On le garde ta mega fonction pour sortir le fichier CSV ? :p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge differents data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each university we compute the sum of 'Approved amount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_swiss_universities = pd.merge(\n",
    "    snsf_data_swiss[['University', 'Approved Amount']],\n",
    "    match_location[['University', 'Canton']],\n",
    "    on=['University'],\n",
    "    how='inner'\n",
    ")\n",
    "data_swiss_universities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_university = data_swiss_universities.groupby('University').sum()\n",
    "amount_by_university.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cantons we compute the sum of 'Approved amount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_cantons = data_swiss_universities.groupby('Canton').sum()\n",
    "amount_by_cantons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_cantons.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can notice the difference between the max and the min is huge. <br/> the vizualisation is not going to be very representative (with few colors variations) if we take those values. <br/>\n",
    "\n",
    "\n",
    "> For the reason we decide to apply the fourth root on values in order to reduce the gap between the amount of money given to each cantons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_cantons['Approved Amount Reduced'] = pow(amount_by_cantons['Approved Amount'], 1/5)\n",
    "amount_by_cantons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cantons_data = pd.DataFrame({\n",
    "        'Canton': cantons_id\n",
    "    })\n",
    "cantons_data.set_index('Canton', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the value for each canton, as we can notice in our data some canton does not appear.\n",
    "> We need to add them with a Appoved Amount equals to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_by_all_cantons = pd.merge(cantons_data, amount_by_cantons, right_index=True, left_index=True, how='left')\n",
    "amount_by_all_cantons.fillna(0, inplace=True)\n",
    "amount_by_all_cantons.reset_index(inplace=True)\n",
    "amount_by_all_cantons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We build the map from the data got before.\n",
    "map_final = folium.Map(location=[46.8, 8.1], zoom_start=8)\n",
    "\n",
    "# You need to have the locale 'fr_CH.utf8' or 'fr_CH.UTF-8' install\n",
    "try:\n",
    "    locale.setlocale(locale.LC_MONETARY, 'fr_CH.utf8') # Linux locale\n",
    "except:\n",
    "    try:\n",
    "       locale.setlocale(locale.LC_MONETARY, 'fr_CH.UTF-8') # Mac locale\n",
    "    except:\n",
    "        print('Unable to set fr_CH.utf8 or fr_CH.UTF-8 locale, the currency will not be correct')\n",
    "\n",
    "# Add marker of universities\n",
    "universities_locations = match_location.set_index('University')[['Latitude', 'Longitude']].dropna()\n",
    "for university, row in universities_locations.iterrows():\n",
    "    amount = amount_by_university.loc[university]['Approved Amount']\n",
    "    message = university + ' (' + locale.currency( amount, grouping=True ) + ')'\n",
    "    marker = folium.Marker(row[['Latitude', 'Longitude']], popup=message)\n",
    "    map_final.add_children(marker)\n",
    "    \n",
    "value_column = 'Approved Amount Reduced'\n",
    "\n",
    "scale = list(\n",
    "    np.linspace(\n",
    "        amount_by_all_cantons[value_column].min(),\n",
    "        amount_by_all_cantons[value_column].max(),\n",
    "        6\n",
    "    )\n",
    ")\n",
    "\n",
    "map_final.choropleth(\n",
    "    geo_path=topojson_cantons,\n",
    "    data=amount_by_all_cantons,\n",
    "    columns=['Canton', value_column],\n",
    "    key_on='feature.id',\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    threshold_scale=scale,\n",
    "    legend_name='the fourth root of grant money by Swiss universities canton',\n",
    "    topojson='objects.cantons'\n",
    ")\n",
    "\n",
    "map_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Legend\n",
    "\n",
    ">> Colors: the fourth root of grant money by Swiss universities canton\n",
    "\n",
    ">> Markers: university names with the grant money"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "15079bc63e95481b82326ee0717671d6": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "191a783b301440a290cb46c945be1d3e": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "4166b5f5094348f0baf16159c78a9edc": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
